{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech to Text\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "from google.cloud import speech\n",
    "from google.cloud.speech import enums\n",
    "from google.cloud.speech import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Google Seepch API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = '/Users/YOUR-USER/Documents/Future/GOOGLE/YOUR-PROJECT.json'\n",
    "client = speech.SpeechClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Number of Files Under File Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Files: 79\n"
     ]
    }
   ],
   "source": [
    "path = '../testing/wav_converted_files/'\n",
    "wav_files = []\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith('.wav'):\n",
    "        wav_files.append(file)\n",
    "print(f'Number of Files: {len(wav_files)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests a Specific Audio File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Width: 2\n",
      "Channel Count: 1\n",
      "Duration: 5.45s\n",
      "Sample Rate: 22050\n"
     ]
    }
   ],
   "source": [
    "sound_file = AudioSegment.from_file('../testing/wav_converted_files/' + str(wav_files[0]), format=\"wav\")\n",
    "\n",
    "print(f'Sample Width: {sound_file.sample_width}')\n",
    "print(f'Channel Count: {sound_file.channels}')\n",
    "print(f'Duration: {len(sound_file) / 1000}s')\n",
    "print(f'Sample Rate: {sound_file.frame_rate}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Speech to Text - Google API + Streets Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refresh stored variables from previous notebooks\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_speech_to_text(path):\n",
    "    \n",
    "    '''Converts audio files under selected folder to text and returns a DataFrame'''\n",
    "\n",
    "    # Create list to house data on every loop\n",
    "    list_results = []\n",
    "\n",
    "    # Loop through all files in path provided\n",
    "    for n, file in enumerate(os.listdir(path)):\n",
    "    \n",
    "        t1 = time.time()\n",
    "        \n",
    "        # Select only the ones with extension '.wav'\n",
    "        if file.endswith('.wav'):\n",
    "            \n",
    "            # Instantiate dictionary\n",
    "            d = {}\n",
    "            \n",
    "            # Instantiates a client\n",
    "            client = speech.SpeechClient()\n",
    "\n",
    "            # Loads the audio into memory\n",
    "            with io.open(path + file, 'rb') as audio_file:\n",
    "                content = audio_file.read()\n",
    "                audio = types.RecognitionAudio(content=content)\n",
    "\n",
    "            # Configure recognition parameters\n",
    "            config = types.RecognitionConfig(\n",
    "                encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "                sample_rate_hertz=22050,\n",
    "                language_code='en-US',\n",
    "                audio_channel_count=1,\n",
    "                model = 'video',\n",
    "                speech_contexts= [{'phrases': streets_list}],\n",
    "            )\n",
    "\n",
    "            # Detects speech in the audio file\n",
    "            response = client.recognize(config, audio)\n",
    "\n",
    "            # Create string to house pieces returned by result\n",
    "            string = ''\n",
    "            list_confidence = []\n",
    "\n",
    "            # Loop through results\n",
    "            for result in response.results:\n",
    "\n",
    "                # if lenght is greater than 0\n",
    "                if len(result.alternatives[0].transcript) > 0:\n",
    "\n",
    "                    # Append to list\n",
    "                    string = string + result.alternatives[0].transcript\n",
    "                    list_confidence.append(result.alternatives[0].confidence)\n",
    "            \n",
    "            # Create key/value pair for dictionary                      \n",
    "            d['transcripts'] = string\n",
    "            d['confidence'] = np.mean(list_confidence)\n",
    "\n",
    "            # Append dictionary to list\n",
    "            list_results.append(d)\n",
    "            \n",
    "            # Print RunTime\n",
    "            print(f'File {n} RunTime: {round(time.time() - t1, 2)}s')\n",
    "    \n",
    "    # Create DataFrame with list_results\n",
    "    df = pd.DataFrame(list_results)\n",
    "\n",
    "    # Return DataFrame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create DataFrame from Speech To Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 0 RunTime: 8.68s\n",
      "File 1 RunTime: 4.26s\n",
      "File 2 RunTime: 5.84s\n",
      "File 3 RunTime: 4.22s\n",
      "File 4 RunTime: 5.44s\n",
      "File 5 RunTime: 6.09s\n",
      "File 6 RunTime: 7.92s\n",
      "File 7 RunTime: 27.17s\n",
      "File 8 RunTime: 5.91s\n",
      "File 9 RunTime: 16.46s\n",
      "File 10 RunTime: 7.4s\n",
      "File 11 RunTime: 23.72s\n",
      "File 12 RunTime: 9.09s\n",
      "File 13 RunTime: 38.26s\n",
      "File 15 RunTime: 10.95s\n",
      "File 16 RunTime: 6.15s\n",
      "File 17 RunTime: 5.05s\n",
      "File 18 RunTime: 10.27s\n",
      "File 19 RunTime: 5.3s\n",
      "File 20 RunTime: 5.75s\n",
      "File 21 RunTime: 7.47s\n",
      "File 22 RunTime: 4.81s\n",
      "File 23 RunTime: 9.08s\n",
      "File 24 RunTime: 5.09s\n",
      "File 25 RunTime: 8.04s\n",
      "File 26 RunTime: 6.36s\n",
      "File 27 RunTime: 5.33s\n",
      "File 28 RunTime: 11.47s\n",
      "File 29 RunTime: 7.03s\n",
      "File 30 RunTime: 13.3s\n",
      "File 31 RunTime: 5.56s\n",
      "File 32 RunTime: 7.95s\n",
      "File 33 RunTime: 7.1s\n",
      "File 34 RunTime: 5.89s\n",
      "File 35 RunTime: 12.9s\n",
      "File 36 RunTime: 25.9s\n",
      "File 37 RunTime: 31.24s\n",
      "File 38 RunTime: 9.7s\n",
      "File 39 RunTime: 8.45s\n",
      "File 40 RunTime: 11.4s\n",
      "File 41 RunTime: 6.86s\n",
      "File 42 RunTime: 12.88s\n",
      "File 43 RunTime: 6.11s\n",
      "File 44 RunTime: 17.14s\n",
      "File 45 RunTime: 7.88s\n",
      "File 46 RunTime: 9.76s\n",
      "File 47 RunTime: 4.61s\n",
      "File 48 RunTime: 255.36s\n",
      "File 49 RunTime: 10.5s\n",
      "File 50 RunTime: 7.27s\n",
      "File 51 RunTime: 8.47s\n",
      "File 52 RunTime: 5.51s\n",
      "File 53 RunTime: 19.89s\n",
      "File 54 RunTime: 6.16s\n",
      "File 55 RunTime: 13.31s\n",
      "File 56 RunTime: 11.68s\n",
      "File 57 RunTime: 8.06s\n",
      "File 58 RunTime: 9.09s\n",
      "File 59 RunTime: 23.95s\n",
      "File 60 RunTime: 6.99s\n",
      "File 61 RunTime: 9.75s\n",
      "File 62 RunTime: 13.69s\n",
      "File 63 RunTime: 7.53s\n",
      "File 64 RunTime: 9.22s\n",
      "File 65 RunTime: 6.77s\n",
      "File 66 RunTime: 7.53s\n",
      "File 67 RunTime: 20.38s\n",
      "File 68 RunTime: 11.78s\n",
      "File 69 RunTime: 7.75s\n",
      "File 70 RunTime: 8.52s\n",
      "File 71 RunTime: 7.57s\n",
      "File 72 RunTime: 14.06s\n",
      "File 73 RunTime: 10.47s\n",
      "File 74 RunTime: 4.59s\n",
      "File 75 RunTime: 6.47s\n",
      "File 76 RunTime: 6.03s\n",
      "File 77 RunTime: 5.1s\n",
      "File 78 RunTime: 12.97s\n",
      "File 79 RunTime: 10.33s\n"
     ]
    }
   ],
   "source": [
    "df = google_speech_to_text('../testing/wav_converted_files/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop NaN Values / Blank Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transcripts'] = df['transcripts'].map(lambda x: x.replace(':','').strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Total Confidence on Speech to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78996"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.mean(df['confidence']),5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['transcripts'].map(lambda x: x.lower().split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcripts</th>\n",
       "      <th>confidence</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>we going to call Joe at the corner of BP's and Taraval</td>\n",
       "      <td>0.807508</td>\n",
       "      <td>[we, going, to, call, joe, at, the, corner, of, bp's, and, taraval]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Flora ways for a 14 year old male conscious breathing laceration to the inside of his</td>\n",
       "      <td>0.832525</td>\n",
       "      <td>[flora, ways, for, a, 14, year, old, male, conscious, breathing, laceration, to, the, inside, of, his]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>40th the Safeway Taraval 730 Taraval top of seventies and eighties is possibly related and that because of EMA</td>\n",
       "      <td>0.793670</td>\n",
       "      <td>[40th, the, safeway, taraval, 730, taraval, top, of, seventies, and, eighties, is, possibly, related, and, that, because, of, ema]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>for 390 building across the hide in marking the language</td>\n",
       "      <td>0.766427</td>\n",
       "      <td>[for, 390, building, across, the, hide, in, marking, the, language]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>negative about we split up Partners it's my music Concourse I am at a company G work</td>\n",
       "      <td>0.827363</td>\n",
       "      <td>[negative, about, we, split, up, partners, it's, my, music, concourse, i, am, at, a, company, g, work]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                      transcripts  \\\n",
       "0                                                          we going to call Joe at the corner of BP's and Taraval   \n",
       "1                           Flora ways for a 14 year old male conscious breathing laceration to the inside of his   \n",
       "2  40th the Safeway Taraval 730 Taraval top of seventies and eighties is possibly related and that because of EMA   \n",
       "3                                                        for 390 building across the hide in marking the language   \n",
       "4                            negative about we split up Partners it's my music Concourse I am at a company G work   \n",
       "\n",
       "   confidence  \\\n",
       "0    0.807508   \n",
       "1    0.832525   \n",
       "2    0.793670   \n",
       "3    0.766427   \n",
       "4    0.827363   \n",
       "\n",
       "                                                                                                                               tokens  \n",
       "0                                                                 [we, going, to, call, joe, at, the, corner, of, bp's, and, taraval]  \n",
       "1                              [flora, ways, for, a, 14, year, old, male, conscious, breathing, laceration, to, the, inside, of, his]  \n",
       "2  [40th, the, safeway, taraval, 730, taraval, top, of, seventies, and, eighties, is, possibly, related, and, that, because, of, ema]  \n",
       "3                                                                 [for, 390, building, across, the, hide, in, marking, the, language]  \n",
       "4                              [negative, about, we, split, up, partners, it's, my, music, concourse, i, am, at, a, company, g, work]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Clean DataFrame to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/transcripts.csv', index_label=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
