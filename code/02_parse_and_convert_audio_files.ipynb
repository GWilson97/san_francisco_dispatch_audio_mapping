{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse and Convert Audio Files\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pydub\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence, detect_silence\n",
    "from pydub.playback import play\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define ffmpeg and ffprobe Path for PyDub Converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pydub.AudioSegment.converter = '/Users/YOUR-USER/anaconda3/bin/ffmpeg'\n",
    "pydub.AudioSegment.ffmpeg = '/Users/YOUR-USER/anaconda3/bin/ffmpeg'\n",
    "pydub.AudioSegment.ffprobe = '/Users/YOUR-USER/anaconda3/bin/ffprobe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the pydub Python package to parse and segment our mp3 files. Pydub accepts mp3 files and has methods that detect silence, detect audio, and split the mp3 files based on silence. We utilized the last method to pull samples of audio from our data. There are two parameters we passed in as well -- min_silence_len and silence_thresh. These determine how long a pause needs to be in milliseconds before itâ€™s registered as silence, and how loud something needs to be in dbFS before its registered as audio. We played with a few min_silence_len and silence_thresh values, but settled on 2.5 seconds and -16dbFS for our dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse Through Files and Convert to .wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing File: 0\n",
      "File Lenght: 771.997s\n",
      "File Average Loudness: -23.66 dBFS\n"
     ]
    }
   ],
   "source": [
    "# Starting time\n",
    "t0 = time.time()\n",
    "\n",
    "# Insert file path with mp3 downloads\n",
    "file_path = '../testing/mp3_downloads/'\n",
    "\n",
    "# Loop through all files in file_path\n",
    "for n, file in enumerate(os.listdir(file_path)):\n",
    "    \n",
    "    # Starting time\n",
    "    t1 = time.time()\n",
    "    \n",
    "    # If file extension is .mp3\n",
    "    if file.endswith('.mp3'):\n",
    "        \n",
    "        # Define audio to be split\n",
    "        sound_file = AudioSegment.from_mp3(file_path + file)\n",
    "        \n",
    "        # Print file n, lenght and avg loudness for each file\n",
    "        print(f'Analyzing File: {n}')\n",
    "        print(f'File Lenght: {len(sound_file) / 1000}s')\n",
    "        print(f'File Average Loudness: {round(sound_file.dBFS, 2)} dBFS')\n",
    "        \n",
    "                \n",
    "        # Split files into smaller chunks\n",
    "        chunks = split_on_silence(sound_file,                           # sound_file to be split\n",
    "                                  min_silence_len = 4_000,              # min_silence_len in ms\n",
    "                                  silence_thresh = sound_file.dBFS - 2, # silence thresh based on avg loudness\n",
    "                                  keep_silence = 100)                   # add 100ms of silence before and after\n",
    "        \n",
    "        # Loop through all chunks and select the ones that are at least 2 seconds and less than 60 seconds\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            \n",
    "            #  Export chunks to that are at least 5 seconds and less than 60 seconds to .wav\n",
    "            if (len(chunk) > 5_000) and (len(chunk) < 60_000):\n",
    "                chunk.export(f\"./testing/wav_converted_files/{file}_{i}.wav\", format=\"wav\")\n",
    "        \n",
    "        # Starting time\n",
    "        print(f'File {n} RunTime: {round(time.time() - t1, 2)}s')\n",
    "        print(' ')\n",
    "        \n",
    "# Print total runtime\n",
    "print(f'Total RunTime:{round(time.time() - t0, 2)}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Adapted from:** [Mitchell Bohman, Nour Zahlan, and Masiur Abik](https://github.com/mchbmn/radio-to-location) and [Joseph Hopkins, Carol, Chiu, Anthony Chapman, Kwamae Delva](https://github.com/delvakwa/police_radio_to_mapping)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
